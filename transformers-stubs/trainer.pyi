from typing import Optional, Dict, Tuple, Union, Any, Callable
from . import PreTrainedModel, TrainingArguments
from torch.utils.data.dataset import Dataset
from tqdm import tqdm
import torch
from torch import nn
from torch.utils.data.dataloader import DataLoader

from .trainer_utils import TrainOutput, PredictionOutput, EvalPrediction

class Trainer:
    def __init__(
        self,
        model: PreTrainedModel,
        args: TrainingArguments,
        # data_collator: Optional[DataCollator] = None,
        train_dataset: Optional[Dataset] = None,
        eval_dataset: Optional[Dataset] = None,
        compute_metrics: Optional[Callable[[EvalPrediction], Dict[str, float]]] = None,
        # prediction_loss_only: bool=False,
        # tb_writer: Optional["SummaryWriter"] = None,
        # optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (
        #     None,
        #     None,
        # ),
    ): ...
    # def get_train_dataloader(self) -> DataLoader: ...
    # def get_eval_dataloader(self, eval_dataset: Optional[Dataset] = None) -> DataLoader: ...

    # def get_test_dataloader(self, test_dataset: Dataset) -> DataLoader: ...

    # def create_optimizer_and_scheduler(self, num_training_steps: int): ...

    # def setup_wandb(self): ...
    # def num_examples(self, dataloader: DataLoader) -> int: ...
    def train(self, model_path: Optional[str] = None) -> TrainOutput: ...
    def log(self, logs: Dict[str, float], iterator: Optional[tqdm] = None) -> None: ...
    def training_step(
        self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]
    ) -> float: ...
    # def is_local_master(self) -> bool: ...
    # def is_local_process_zero(self) -> bool: ...
    def is_world_master(self) -> bool: ...
    def is_world_process_zero(self) -> bool: ...
    def save_model(self, output_dir: Optional[str] = None) -> None: ...
    def evaluate(self, eval_dataset: Optional[Dataset] = None) -> Dict[str, float]: ...
    def predict(self, test_dataset: Dataset) -> PredictionOutput: ...
    def prediction_loop(
        self,
        dataloader: DataLoader,
        description: str,
        prediction_loss_only: Optional[bool] = None,
    ) -> PredictionOutput: ...
    def distributed_concat(
        self, tensor: torch.Tensor, num_total_examples: int
    ) -> torch.Tensor: ...
    def prediction_step(
        self,
        model: nn.Module,
        inputs: Dict[str, Union[torch.Tensor, Any]],
        prediction_loss_only: bool,
    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: ...
